{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchdeepretina as tdr\n",
    "from torchinfo import summary\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"naturalscene/15-11-21b_naturalscene.pt\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VaryModel(\n",
      "  n_units=17, noise=0.05, bias=True, gc_bias=False, chans=[8, 8], bn_moment=0.01, softplus=True, inference_exp=False, img_shape=[40, 50, 50], ksizes=[15, 11, 11]\n",
      "  (sequential): Sequential(\n",
      "    (0): LinearStackedConv2d(\n",
      "      bias=True, abs_bnorm=False, padding=0\n",
      "      (convs): Sequential(\n",
      "        (0): Conv2d(40, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (1): Dropout(p=0.05, inplace=False)\n",
      "        (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (3): Dropout(p=0.05, inplace=False)\n",
      "        (4): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (5): Dropout(p=0.05, inplace=False)\n",
      "        (6): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (7): Dropout(p=0.05, inplace=False)\n",
      "        (8): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (9): Dropout(p=0.05, inplace=False)\n",
      "        (10): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (11): Dropout(p=0.05, inplace=False)\n",
      "        (12): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (1): AbsBatchNorm2d(bias=True, abs_bias=False, momentum=0.01, eps=0.001)\n",
      "    (2): GaussianNoise(std=0.05, trainable=False, adapt=False, momentum=None)\n",
      "    (3): ReLU()\n",
      "    (4): LinearStackedConv2d(\n",
      "      bias=True, abs_bnorm=False, padding=0\n",
      "      (convs): Sequential(\n",
      "        (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (1): Dropout(p=0.05, inplace=False)\n",
      "        (2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (3): Dropout(p=0.05, inplace=False)\n",
      "        (4): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (5): Dropout(p=0.05, inplace=False)\n",
      "        (6): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "        (7): Dropout(p=0.05, inplace=False)\n",
      "        (8): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1))\n",
      "      )\n",
      "    )\n",
      "    (5): AbsBatchNorm2d(bias=True, abs_bias=False, momentum=0.01, eps=0.001)\n",
      "    (6): GaussianNoise(std=0.05, trainable=False, adapt=False, momentum=None)\n",
      "    (7): ReLU()\n",
      "    (8): Conv2d(8, 17, kernel_size=(11, 11), stride=(1, 1), bias=False)\n",
      "    (9): GrabUnits(\n",
      "      c0: tensor([0, 0]),\n",
      "      c1: tensor([2, 0]),\n",
      "      c2: tensor([1, 0]),\n",
      "      c3: tensor([1, 0]),\n",
      "      c4: tensor([3, 0]),\n",
      "      c5: tensor([4, 0]),\n",
      "      c6: tensor([3, 0]),\n",
      "      c7: tensor([7, 0]),\n",
      "      c8: tensor([5, 0]),\n",
      "      c9: tensor([8, 0]),\n",
      "      c10: tensor([6, 0]),\n",
      "      c11: tensor([8, 0]),\n",
      "      c12: tensor([9, 0]),\n",
      "      c13: tensor([8, 0]),\n",
      "      c14: tensor([9, 0]),\n",
      "      c15: tensor([8, 0]),\n",
      "      c16: tensor([6, 0])\n",
      "    )\n",
      "    (10): AbsBatchNorm1d(bias=True, abs_bias=False, momentum=0.01, eps=0.001)\n",
      "    (11): Softplus(beta=1.0, threshold=20.0)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "for model in models:\n",
    "    model_path = os.path.join(\"../models/\", model)\n",
    "    model = tdr.io.load_model(model_path)\n",
    "    model.eval()\n",
    "    print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "VaryModel                                [1, 17]                   --\n",
       "├─Sequential: 1-1                        [1, 17]                   --\n",
       "│    └─LinearStackedConv2d: 2-1          [1, 8, 36, 36]            --\n",
       "│    │    └─Sequential: 3-1              [1, 8, 36, 36]            6,344\n",
       "│    └─AbsBatchNorm2d: 2-2               [1, 8, 36, 36]            32\n",
       "│    └─GaussianNoise: 2-3                [1, 8, 36, 36]            (1)\n",
       "│    └─ReLU: 2-4                         [1, 8, 36, 36]            --\n",
       "│    └─LinearStackedConv2d: 2-5          [1, 8, 26, 26]            --\n",
       "│    │    └─Sequential: 3-2              [1, 8, 26, 26]            2,888\n",
       "│    └─AbsBatchNorm2d: 2-6               [1, 8, 26, 26]            32\n",
       "│    └─GaussianNoise: 2-7                [1, 8, 26, 26]            (1)\n",
       "│    └─ReLU: 2-8                         [1, 8, 26, 26]            --\n",
       "│    └─Conv2d: 2-9                       [1, 17, 16, 16]           16,456\n",
       "│    └─GrabUnits: 2-10                   [1, 17]                   --\n",
       "│    └─AbsBatchNorm1d: 2-11              [1, 17]                   68\n",
       "│    └─Softplus: 2-12                    [1, 17]                   --\n",
       "==========================================================================================\n",
       "Total params: 25,822\n",
       "Trainable params: 25,820\n",
       "Non-trainable params: 2\n",
       "Total mult-adds (Units.MEGABYTES): 19.33\n",
       "==========================================================================================\n",
       "Input size (MB): 0.40\n",
       "Forward/backward pass size (MB): 1.38\n",
       "Params size (MB): 0.10\n",
       "Estimated Total Size (MB): 1.88\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model, input_size=(1, 40, 50, 50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuro",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
